{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多层感知机的从零实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = d2l.FashionMNIST(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = dataset.get_dataloader(train=True)\n",
    "test_iter = dataset.get_dataloader(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_iter:\n",
    "    print(X.shape, y.shape)\n",
    "    print(np.unique(y))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.W = torch.normal(0, 0.01, size=(input_size, output_size), requires_grad=True)\n",
    "        self.b = torch.zeros(output_size, requires_grad=True)\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "    def __call__(self, H):\n",
    "        return H @ self.W +self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 激活层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(H):\n",
    "    return 1 / (1 + torch.exp(H))\n",
    "def ReLu(H):\n",
    "    H[H<0] = 0\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义SoftMax层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SoftMax(H: torch.Tensor):\n",
    "    expH = torch.exp(H)\n",
    "    return expH / expH.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self):\n",
    "        self.Sequential = [\n",
    "            ('01-linear(784, 1000)', Linear(28*28, 1000)), \n",
    "            ('02-ReLu', ReLu),\n",
    "            ('03-linear(1000, 100)', Linear(1000, 100)),\n",
    "            ('04-ReLu',ReLu),\n",
    "            ('05-Linear(100, 10)', Linear(100, 10)), \n",
    "            ('06-SoftMax', SoftMax)\n",
    "        ]\n",
    "\n",
    "    def show(self, X):\n",
    "        for layner_name, layer in self.Sequential:\n",
    "            print(f\"{layner_name:30}{X.shape}\", end=' -> ')\n",
    "            X = layer(X)\n",
    "            print(X.shape)\n",
    "        return X\n",
    "\n",
    "    def get_params(self):\n",
    "        \"\"\"获取神经网络中全部参数\"\"\"\n",
    "        params = []\n",
    "        for _, layer in self.Sequential:\n",
    "            if 'params' in layer.__dict__:\n",
    "                params.extend(layer.params)\n",
    "        return params\n",
    "\n",
    "    def __call__(self, X):\n",
    "        for _, layer in self.Sequential:\n",
    "            X = layer(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.6259e-01, 3.0952e-03],\n",
       "        [9.4124e-01, 6.5784e-02],\n",
       "        [1.5199e+00, 1.2847e-01],\n",
       "        [2.0985e+00, 1.9116e-01],\n",
       "        [2.6772e+00, 2.5385e-01],\n",
       "        [3.2558e+00, 3.1654e-01],\n",
       "        [3.8345e+00, 3.7923e-01],\n",
       "        [4.4131e+00, 4.4192e-01],\n",
       "        [4.9918e+00, 5.0460e-01],\n",
       "        [5.5704e+00, 5.6729e-01]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = Linear(10, 2)\n",
    "H = torch.arange(100, dtype=torch.float32).reshape(-1, 10)\n",
    "linear(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLP()\n",
    "params = net.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-linear(784, 1000)          torch.Size([5, 784]) -> torch.Size([5, 1000])\n",
      "02-ReLu                       torch.Size([5, 1000]) -> torch.Size([5, 1000])\n",
      "03-linear(1000, 100)          torch.Size([5, 1000]) -> torch.Size([5, 100])\n",
      "04-ReLu                       torch.Size([5, 100]) -> torch.Size([5, 100])\n",
      "05-Linear(100, 10)            torch.Size([5, 100]) -> torch.Size([5, 10])\n",
      "06-SoftMax                    torch.Size([5, 10]) -> torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.normal(0, 0.1, size=(5, 28*28))\n",
    "y = net.show(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784, 1000])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param in params:\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[-1].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.4486e-09, 7.4497e-09, 7.4506e-09, 7.4537e-09, 7.4535e-09, 7.4533e-09,\n",
       "        7.4509e-09, 7.4505e-09, 7.4501e-09, 7.4509e-09])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.backward()\n",
    "params[-1].grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat[range(len(y_hat)), y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
